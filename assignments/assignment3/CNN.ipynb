{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3.1 - Сверточные нейронные сети (Convolutional Neural Networks)\n",
    "\n",
    "Это последнее задание на numpy, вы до него дожили! Остался последний марш-бросок, дальше только PyTorch.\n",
    "\n",
    "В этом задании вы реализуете свою собственную сверточную нейронную сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer, ConvolutionalLayer, MaxPoolingLayer, Flattener\n",
    "from model import ConvNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "На этот раз мы не будем их преобразовывать в один вектор, а оставим размерности (num_samples, 32, 32, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):    \n",
    "    train_X = train_X.astype(np.float) / 255.0\n",
    "    test_X = test_X.astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_X, axis = 0)\n",
    "    train_X -= mean_image\n",
    "    test_X -= mean_image\n",
    "    \n",
    "    return train_X, test_X\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализуем новые слои!\n",
    "\n",
    "Сначала основной новый слой - сверточный (Convolutional layer). \n",
    "Для начала мы реализуем его для только одного канала, а потом для нескольких.\n",
    "\n",
    "Сверточный слой выполняет операцию свертки (convolution) с весами для каждого канала, а потом складывает результаты. \n",
    "Возможно, поможет пересмотреть Лекцию 6 или внимательно прочитать\n",
    "http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "Один из подходов к реализации сверточного слоя основан на том, что для конкретного \"пикселя\" выхода применение сверточного слоя эквивалентно обычному полносвязному.  \n",
    "Рассмотрим один такой \"пиксель\":\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Он получает на вход   \n",
    "регион входа I размера `(batch_size, filter_size, filter_size, input_channels)`,  \n",
    "применяет к нему веса W `(filter_size, filter_size, input_channels, output_channels`\n",
    "и выдает `(batch_size, output_channels)`. \n",
    "\n",
    "Если:  \n",
    "- вход преобразовать в I' `(batch_size, filter_size*filter_size*input_channels)`,  \n",
    "- веса в W' `(filter_size*filter_size*input_channels, output_channels)`,  \n",
    "то выход \"пикселе\" будет эквивалентен полносвязному слою со входом I' и весами W'.\n",
    "\n",
    "Осталось выполнить его в цикле для каждого пикселя :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (2, 2, 2, 1)\n",
      "Shape of W (2, 2, 1, 1)\n",
      "Shape of X: (2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ConvolutionaLayer that supports only 1 output and input channel\n",
    "\n",
    "# Note: now you're working with images, so X is 4-dimensional tensor of\n",
    "# (batch_size, height, width, channels)\n",
    "\n",
    "X = np.array([\n",
    "              [\n",
    "               [[1.0], [2.0]],\n",
    "               [[0.0], [-1.0]]\n",
    "              ]\n",
    "              ,\n",
    "              [\n",
    "               [[0.0], [1.0]],\n",
    "               [[-2.0], [-1.0]]\n",
    "              ]\n",
    "             ])\n",
    "\n",
    "# Batch of 2 images of dimensions 2x2 with a single channel\n",
    "print(\"Shape of X:\",X.shape)\n",
    "\n",
    "layer = ConvolutionalLayer(in_channels=1, out_channels=1, filter_size=2, padding=0)\n",
    "print(\"Shape of W\", layer.W.value.shape)\n",
    "layer.W.value = np.zeros_like(layer.W.value)\n",
    "layer.W.value[0, 0, 0, 0] = 1.0\n",
    "layer.B.value = np.ones_like(layer.B.value)\n",
    "result = layer.forward(X)\n",
    "\n",
    "assert result.shape == (2, 1, 1, 1)\n",
    "assert np.all(result == X[:, :1, :1, :1] +1), \"result: %s, X: %s\" % (result, X[:, :1, :1, :1])\n",
    "\n",
    "\n",
    "# Now let's implement multiple output channels\n",
    "layer = ConvolutionalLayer(in_channels=1, out_channels=2, filter_size=2, padding=0)\n",
    "result = layer.forward(X)\n",
    "assert result.shape == (2, 1, 1, 2)\n",
    "\n",
    "\n",
    "# And now multple input channels!\n",
    "X = np.array([\n",
    "              [\n",
    "               [[1.0, 0.0], [2.0, 1.0]],\n",
    "               [[0.0, -1.0], [-1.0, -2.0]]\n",
    "              ]\n",
    "              ,\n",
    "              [\n",
    "               [[0.0, 1.0], [1.0, -1.0]],\n",
    "               [[-2.0, 2.0], [-1.0, 0.0]]\n",
    "              ]\n",
    "             ])\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "result = layer.forward(X)\n",
    "assert result.shape == (2, 1, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## А теперь имплементируем обратный проход\n",
    "Возможно, это самое сложное место в курсе. Дальше будет лучше.\n",
    "\n",
    "Раз выполнение сверточного слоя эквивалентно полносвязному слою для каждого \"пикселя\" выхода, то общий обратный проход эквивалентен обратному проходу каждого из таких \"слоев\".  \n",
    "Градиенты от каждого из этих \"слоев\" в каждом пикселе надо сложить в соответствующие пиксели градиента по входу, а градиенты весов сложить все вместе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# First test - check the shape is right\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "result = layer.forward(X)\n",
    "d_input = layer.backward(np.ones_like(result))\n",
    "assert d_input.shape == X.shape\n",
    "\n",
    "# Actually test the backward pass\n",
    "# As usual, you'll need to copy gradient check code from the previous assignment\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "assert check_layer_gradient(layer, X)\n",
    "\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "assert check_layer_param_gradient(layer, X, 'W')\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "assert check_layer_param_gradient(layer, X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось реализовать дополнение нулями (padding).   \n",
    "Достаточно дополнить входной тензор нулями по сторонам. Не забудьте учесть это при обратном проходе!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=3, padding=1)\n",
    "result = layer.forward(X)\n",
    "# Note this kind of layer produces the same dimensions as input\n",
    "assert result.shape == X.shape,\"Result shape: %s - Expected shape %s\" % (result.shape, X.shape)\n",
    "d_input = layer.backward(np.ones_like(result))\n",
    "assert d_input.shape == X.shape\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=3, padding=1)\n",
    "assert check_layer_gradient(layer, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## После следующего слоя вам уже будет все ни по чем - max pooling\n",
    "\n",
    "Max Pooling - это слой, реализующий операцию максимума для каждого канала отдельно в окресности из `pool_size` \"пикселей\".\n",
    "\n",
    "![image](https://upload.wikimedia.org/wikipedia/commons/e/e9/Max_pooling.png)\n",
    "\n",
    "И напомним что такое stride.  \n",
    "Stride - это на сколько \"пикселей\" сдвигается окно на одном шаге.  \n",
    "Вот здесь, например, stride = 2\n",
    "\n",
    "![image.png](http://deeplearning.net/software/theano/_images/no_padding_strides.gif)\n",
    "\n",
    "На практике, для max pooling значение stride часто равно pool size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 1, 2)\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "pool = MaxPoolingLayer(2, 2)\n",
    "result = pool.forward(X)\n",
    "print(result.shape)\n",
    "assert result.shape == (2, 1, 1, 2)\n",
    "\n",
    "assert check_layer_gradient(pool, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И на закуску - слой, преобразующий четырехмерные тензоры в двумерные.\n",
    "\n",
    "Этот слой понадобится нам, чтобы в конце сети перейти от сверточных слоев к полносвязным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "flattener = Flattener()\n",
    "result = flattener.forward(X)\n",
    "\n",
    "assert result.shape == (2,8)\n",
    "\n",
    "assert check_layer_gradient(flattener, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теперь есть все кирпичики, создаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for 0_B\n",
      "Gradient check passed!\n",
      "Checking gradient for 3_W\n",
      "Gradient check passed!\n",
      "Checking gradient for 0_W\n",
      "Gradient check passed!\n",
      "Checking gradient for 7_B\n",
      "Gradient check passed!\n",
      "Checking gradient for 7_W\n",
      "Gradient check passed!\n",
      "Checking gradient for 3_B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement missed functions function for ConvNet model\n",
    "\n",
    "# No need to use L2 regularization\n",
    "model = ConvNet(input_shape=(32,32,3), n_output_classes=10, conv1_channels=2, conv2_channels=2)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оптимизатор и код для тренировки \n",
    "Должен заработать с кодом из прошлого задания без изменений!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302902, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.302832, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.302762, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.302692, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.302622, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.302552, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.302482, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.302413, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.302343, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.302273, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.302203, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.302133, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.302063, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.301993, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.301924, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.301854, Train accuracy: 0.000000, val accuracy: 0.125000\n",
      "Loss: 2.301784, Train accuracy: 0.062500, val accuracy: 0.125000\n",
      "Loss: 2.301714, Train accuracy: 0.062500, val accuracy: 0.125000\n",
      "Loss: 2.301645, Train accuracy: 0.062500, val accuracy: 0.125000\n",
      "Loss: 2.301575, Train accuracy: 0.062500, val accuracy: 0.125000\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(input_shape=(32,32,3), n_output_classes=10, conv1_channels=2, conv2_channels=2)\n",
    "dataset = Dataset(train_X[:16], train_y[:16], val_X[:16], val_y[:16])\n",
    "trainer = Trainer(model, dataset, SGD(), batch_size=16, learning_rate=1e-4)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xb19eb9ba8>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Последнее упражнение\n",
    "В качестве последнего упражнения мы доведем точность на тренировочном наборе данных до 100% на небольшом наборе данных.\n",
    "Сверточные сети требуют большого количества вычислений и аккуратной эффективной реализации, поэтому настоящие модели мы будем тренировать уже на PyTorch в следующем задании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итак, оверфитим маленький набор данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Not implemented!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-e20b22b877f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMomentumSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/workspace/dl_course/assignments/assignment3/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mbatch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/dl_course/assignments/assignment3/optim.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, w, d_w, learning_rate)\u001b[0m\n\u001b[1;32m     27\u001b[0m         '''\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# TODO Copy from the previous assignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not implemented!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: Not implemented!"
     ]
    }
   ],
   "source": [
    "data_size = 128\n",
    "model = ConvNet(input_shape=(32,32,3), n_output_classes=10, conv1_channels=2, conv2_channels=2)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach 1.0 training accuracy in 50 epochs or less\n",
    "# Hint: If you have hard time finding the right parameters manually, try grid search or random search!\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-5, num_epochs=50, batch_size=64)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальнейшие упражнения - уже на PyTorch, открывайте следующий notebook!\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
